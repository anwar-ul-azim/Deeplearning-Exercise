
#model 1

# classifier.add(Convolution2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Convolution2D(64, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Flatten())
# classifier.add(Dense(units=512, activation='relu'))
# classifier.add(Dense(units=24, activation='softmax'))

# output 1

# (keras) G:\asl a dataset\dataset5>python test.py
# Using TensorFlow backend.
# Found 106080 images belonging to 24 classes.
# Found 25588 images belonging to 24 classes.
# Epoch 1/15
# 414/414 [==============================] - 1841s 4s/step - loss: 1.2353 - acc: 0.6240 - val_loss: 1.8102 - val_acc: 0.5441
# Epoch 2/15
# 414/414 [==============================] - 631s 2s/step - loss: 0.5108 - acc: 0.8379 - val_loss: 1.8146 - val_acc: 0.5596
# .................
# Epoch 14/15
# 414/414 [==============================] - 184s 445ms/step - loss: 0.1309 - acc: 0.9566 - val_loss: 2.2141 - val_acc: 0.6212
# Epoch 15/15
# 414/414 [==============================] - 185s 447ms/step - loss: 0.1237 - acc: 0.9584 - val_loss: 1.9271 - val_acc: 0.6482

#output-2

# (keras) G:\asl a dataset\dataset5>python test.py
# Using TensorFlow backend.
# Found 52992 images belonging to 24 classes.
# Found 12782 images belonging to 24 classes.
# Epoch 1/15
# 414/414 [==============================] - 1174s 3s/step - loss: 0.7683 - acc: 0.7673 - val_loss: 1.2332 - val_acc: 0.7079
# Epoch 2/15
# 414/414 [==============================] - 190s 459ms/step - loss: 0.1291 - acc: 0.9595 - val_loss: 1.4044 - val_acc: 0.6549
#...................................
# Epoch 14/15
# 414/414 [==============================] - 193s 466ms/step - loss: 0.0111 - acc: 0.9964 - val_loss: 1.5456 - val_acc: 0.7547
# Epoch 15/15
# 414/414 [==============================] - 197s 477ms/step - loss: 0.0109 - acc: 0.9966 - val_loss: 1.6994 - val_acc: 0.7376

# model 2

# classifier.add(Convolution2D(64, (3, 3), input_shape=(64, 64, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Convolution2D(64, (3, 3), activation='relu'))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(Convolution2D(256, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Convolution2D(256, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Flatten())
# classifier.add(Dense(units=512, activation='relu'))
# classifier.add(Dense(units=24, activation='softmax'))

# output 3

# (keras) G:\asl a dataset\dataset5>python test.py
# Using TensorFlow backend.
# Found 52992 images belonging to 24 classes.
# Found 12782 images belonging to 24 classes.
# Epoch 1/15
# 414/414 [==============================] - 677s 2s/step - loss: 1.0221 - acc: 0.6738 - val_loss: 1.5382 - val_acc: 0.6938
# Epoch 2/15
# 414/414 [==============================] - 305s 736ms/step - loss: 0.1872 - acc: 0.9404 - val_loss: 1.6346 - val_acc: 0.6980
#...........................................
# Epoch 14/15
# 414/414 [==============================] - 199s 480ms/step - loss: 0.0198 - acc: 0.9936 - val_loss: 1.6406 - val_acc: 0.7436
# Epoch 15/15
# 414/414 [==============================] - 198s 477ms/step - loss: 0.0194 - acc: 0.9938 - val_loss: 1.6513 - val_acc: 0.7760

#model 3

# classifier.add(Convolution2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Convolution2D(64, (3, 3), activation='relu'))
# classifier.add(Dropout(0.5))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(Dropout(0.5))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Flatten())
# classifier.add(Dropout(0.5))
# classifier.add(Dense(units=512, activation='relu'))
# classifier.add(Dense(units=24, activation='softmax'))

# output 4

# (keras) G:\asl a dataset\dataset5>python test.py
# Using TensorFlow backend.
# Found 52992 images belonging to 24 classes.
# Found 12782 images belonging to 24 classes.
# Epoch 1/15
## 414/414 [==============================] - 234s 566ms/step - loss: 1.0682 - acc: 0.6724 - val_loss: 1.2903 - val_acc: 0.6835
# Epoch 2/15
# 414/414 [==============================] - 193s 465ms/step - loss: 0.1913 - acc: 0.9387 - val_loss: 1.3160 - val_acc: 0.7047
#...........................................................................
#  Epoch 14/15
# 414/414 [==============================] - 192s 464ms/step - loss: 0.0245 - acc: 0.9920 - val_loss: 1.3613 - val_acc: 0.7507
# Epoch 15/15
# 414/414 [==============================] - 192s 464ms/step - loss: 0.0217 - acc: 0.9928 - val_loss: 1.2561 - val_acc: 0.7743


#model 4

# classifier.add(Convolution2D(64, (3, 3), input_shape=(64, 64, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Convolution2D(256, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Flatten())
# classifier.add(Dense(units=512, activation='relu', kernel_regularizer=regularizers.l2(0.01)))
# classifier.add(Dense(units=24, activation='softmax'))

# output 5

# Found 52992 images belonging to 24 classes.
# Found 12782 images belonging to 24 classes.
# Epoch 1/30
# 414/414 [==============================] - 123s 297ms/step - loss: 1.6952 - acc: 0.6667 - val_loss: 1.6334 - val_acc: 0.6491
# Epoch 2/30
# 414/414 [==============================] - 103s 249ms/step - loss: 0.7855 - acc: 0.8830 - val_loss: 1.6282 - val_acc: 0.6701
# ..........................................
# Epoch 14/30
# 414/414 [==============================] - 100s 240ms/step - loss: 0.3643 - acc: 0.9658 - val_loss: 1.3982 - val_acc: 0.7413
# Epoch 15/30
# 414/414 [==============================] - 114s 276ms/step - loss: 0.3520 - acc: 0.9681 - val_loss: 1.4680 - val_acc: 0.7144




# model 5

# classifier.add(Convolution2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))
# classifier.add(Convolution2D(64, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Dropout(0.3))
# classifier.add(Convolution2D(64, (3, 3), activation='relu'))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Dropout(0.3))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(Convolution2D(256, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Dropout(0.3))
# classifier.add(Flatten())
# classifier.add(Dense(units=512, activation='relu'))
# classifier.add(Dropout(0.3))
# classifier.add(Dense(units=24, activation='softmax'))

# ouput 6

# Found 52992 images belonging to 24 classes.
# Found 12782 images belonging to 24 classes.
# Epoch 1/30
# 414/414 [==============================] - 156s 376ms/step - loss: 1.3528 - acc: 0.5739 - val_loss: 1.1772 - val_acc: 0.7078
# Epoch 2/30
# 414/414 [==============================] - 99s 239ms/step - loss: 0.3945 - acc: 0.8750 - val_loss: 0.9635 - val_acc: 0.7542
#....................................
# Epoch 29/30
# 414/414 [==============================] - 98s 236ms/step - loss: 0.0385 - acc: 0.9876 - val_loss: 1.0962 - val_acc: 0.8116
# Epoch 30/30
# 414/414 [==============================] - 97s 235ms/step - loss: 0.0402 - acc: 0.9869 - val_loss: 1.3832 - val_acc: 0.8183



# ? model 6

# classifier.add(Convolution2D(64, (3, 3), input_shape=(64, 64, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Convolution2D(64, (3, 3), activation='relu'))
# classifier.add(Dropout(0.2))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(Dropout(0.5))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(Dropout(0.2))
# classifier.add(Convolution2D(64, (3, 3), activation='relu'))
# classifier.add(Convolution2D(64, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Flatten())
# classifier.add(Dense(units=512, activation='relu',kernel_regularizer=regularizers.l1(0.01)))
# classifier.add(Dense(units=24, activation='softmax'))

# output 7

# Epoch 1/30
# 414/414 [==============================] - 101s 245ms/step - loss: 21.6177 - acc: 0.3833 - val_loss: 7.0823 - val_acc: 0.4692
# Epoch 2/30
# 414/414 [==============================] - 97s 234ms/step - loss: 5.9604 - acc: 0.6611 - val_loss: 6.3675 - val_acc: 0.5811
# Epoch 3/30
# 414/414 [==============================] - 97s 234ms/step - loss: 5.4447 - acc: 0.7450 - val_loss: 5.9574 - val_acc: 0.6003
# ..........................
# Epoch 7/30
# 414/414 [==============================] - 97s 234ms/step - loss: 4.7319 - acc: 0.8465 - val_loss: 5.1947 - val_acc: 0.6984
# Epoch 8/30
# 414/414 [==============================] - 99s 240ms/step - loss: 4.6597 - acc: 0.8594 - val_loss: 5.5832 - val_acc: 0.6436
# Epoch 9/30
# 414/414 [==============================] - 98s 237ms/step - loss: 4.5760 - acc: 0.8709 - val_loss: 5.8303 - val_acc: 0.6025
# Epoch 10/30
# 414/414 [==============================] - 97s 235ms/step - loss: 4.5536 - acc: 0.8761 - val_loss: 5.7303 - val_acc: 0.6309


# ? model 7

# # adding layers
# classifier.add(Convolution2D(64, (3, 3), input_shape=(64, 64, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Convolution2D(64, (3, 3), activation='relu'))
# classifier.add(Dropout(0.3))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(Dropout(0.3))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(Dropout(0.3))
# classifier.add(Convolution2D(64, (3, 3), activation='relu'))
# classifier.add(Convolution2D(64, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Flatten())
# classifier.add(Dense(units=512, activation='relu',kernel_regularizer=regularizers.l1(0.01)))
# classifier.add(Dense(units=24, activation='softmax'))

# output 8

# Epoch 1/30
# 414/414 [==============================] - 101s 245ms/step - loss: 21.5487 - acc: 0.3836 - val_loss: 7.0100 - val_acc: 0.4022
# Epoch 2/30
# 414/414 [==============================] - 97s 233ms/step - loss: 6.1918 - acc: 0.6271 - val_loss: 6.5868 - val_acc: 0.5077
# ...................................
# Epoch 9/30
# 414/414 [==============================] - 96s 232ms/step - loss: 4.8363 - acc: 0.8445 - val_loss: 5.6668 - val_acc: 0.6375
# Epoch 10/30
# 414/414 [==============================] - 96s 233ms/step - loss: 4.7830 - acc: 0.8535 - val_loss: 5.6407 - val_acc: 0.6513



# ? model 8
# classifier.add(Dense(units=512, activation='relu',kernel_regularizer=regularizers.l2(0.1)))

# output 9

# Epoch 1/30
# 414/414 [==============================] - 107s 258ms/step - loss: 4.1330 - acc: 0.5784 - val_loss: 2.5570 - val_acc: 0.5663
# Epoch 2/30
# 414/414 [==============================] - 101s 243ms/step - loss: 1.4905 - acc: 0.7832 - val_loss: 2.5789 - val_acc: 0.5684
#..........................................
# Epoch 22/30
# 414/414 [==============================] - 97s 235ms/step - loss: 0.4558 - acc: 0.9374 - val_loss: 1.3918 - val_acc: 0.7133
# Epoch 23/30
# 414/414 [==============================] - 98s 237ms/step - loss: 0.4385 - acc: 0.9382 - val_loss: 1.3761 - val_acc: 0.7045


#  ? model 9

# classifier.add(Convolution2D(64, (3, 3), input_shape=(64, 64, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Convolution2D(64, (3, 3), activation='relu'))
# classifier.add(Dropout(0.5))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(Dropout(0.5))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(Dropout(0.5))
# classifier.add(Convolution2D(64, (3, 3), activation='relu'))
# classifier.add(Convolution2D(64, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Flatten())
# classifier.add(Dense(units=512, activation='relu',kernel_regularizer=regularizers.l1(0.005)))
# classifier.add(Dense(units=24, activation='softmax'))

# output 10

# Found 52992 images belonging to 24 classes.
# Found 12782 images belonging to 24 classes.
# Epoch 1/30
# 414/414 [==============================] - 103s 249ms/step - loss: 12.0112 - acc: 0.3684 - val_loss: 4.7603 - val_acc: 0.4412
# Epoch 2/30
# 414/414 [==============================] - 99s 239ms/step - loss: 3.9377 - acc: 0.6472 - val_loss: 4.6166 - val_acc: 0.5044
#...........................................
# Epoch 9/30
# 414/414 [==============================] - 99s 238ms/step - loss: 2.8781 - acc: 0.8365 - val_loss: 3.7189 - val_acc: 0.6291
# Epoch 10/30
# 414/414 [==============================] - 98s 238ms/step - loss: 2.8423 - acc: 0.8426 - val_loss: 3.5430 - val_acc: 0.6581


# ? model 10

# # classifier.add(Dense(units=512, activation='relu',kernel_regularizer=regularizers.l2(0.005)))

# output 11

# Epoch 1/30
# 414/414 [==============================] - 103s 250ms/step - loss: 1.7109 - acc: 0.6359 - val_loss: 1.9092 - val_acc: 0.6506
# Epoch 2/30
# 414/414 [==============================] - 102s 245ms/step - loss: 0.8690 - acc: 0.8809 - val_loss: 1.9716 - val_acc: 0.6704
# Epoch 3/30
# 414/414 [==============================] - 101s 243ms/step - loss: 0.7469 - acc: 0.9127 - val_loss: 1.8832 - val_acc: 0.6705
# Epoch 4/30
# 414/414 [==============================] - 98s 236ms/step - loss: 0.6873 - acc: 0.9236 - val_loss: 1.9424 - val_acc: 0.6507
# Epoch 5/30
# 414/414 [==============================] - 104s 251ms/step - loss: 0.6437 - acc: 0.9337 - val_loss: 1.6688 - val_acc: 0.7017

#  model 11

# ,kernel_regularizer=regularizers.l1(0.01)

# output 12

# 414/414 [==============================] - 102s 245ms/step - loss: 3.4775 - acc: 0.2573 - val_loss: 2.2919 - val_acc: 0.3683
# Epoch 2/30
# 414/414 [==============================] - 98s 236ms/step - loss: 1.4099 - acc: 0.5853 - val_loss: 1.9543 - val_acc: 0.5019
# Epoch 3/30
# 414/414 [==============================] - 103s 249ms/step - loss: 1.0320 - acc: 0.7066 - val_loss: 1.6494 - val_acc: 0.5682
# Epoch 4/30
# 414/414 [==============================] - 315s 761ms/step - loss: 0.8440 - acc: 0.7659 - val_loss: 1.6201 - val_acc: 0.5767

# output 13

# 414/414 [==============================] - 126s 305ms/step - loss: 1.9779 - acc: 0.3701 - val_loss: 1.3345 - val_acc: 0.6318
# Epoch 2/30
# 414/414 [==============================] - 183s 443ms/step - loss: 0.7414 - acc: 0.7622 - val_loss: 1.2104 - val_acc: 0.6821
# Epoch 3/30
# 414/414 [==============================] - 163s 395ms/step - loss: 0.4616 - acc: 0.8525 - val_loss: 1.3514 - val_acc: 0.6748
# Epoch 4/30
# 414/414 [==============================] - 183s 442ms/step - loss: 0.3244 - acc: 0.8967 - val_loss: 1.3049 - val_acc: 0.7067
# Epoch 5/30
# 414/414 [==============================] - 151s 365ms/step - loss: 0.2627 - acc: 0.9158 - val_loss: 1.1799 - val_acc: 0.7369
# Epoch 6/30
# 414/414 [==============================] - 150s 362ms/step - loss: 0.2258 - acc: 0.9279 - val_loss: 1.5320 - val_acc: 0.6991
# Epoch 7/30
# 414/414 [==============================] - 150s 363ms/step - loss: 0.1918 - acc: 0.9379 - val_loss: 1.3684 - val_acc: 0.6859
# Epoch 8/30
# 414/414 [==============================] - 151s 364ms/step - loss: 0.1751 - acc: 0.9441 - val_loss: 1.4222 - val_acc: 0.7239
# Epoch 9/30
# 414/414 [==============================] - 149s 361ms/step - loss: 0.1616 - acc: 0.9474 - val_loss: 1.3941 - val_acc: 0.7508

# output 14

# 414/414 [==============================] - 138s 333ms/step - loss: 4.9210 - acc: 0.3085 - val_loss: 8.1992 - val_acc: 0.2996
# Epoch 2/30
# 414/414 [==============================] - 156s 378ms/step - loss: 10.7538 - acc: 0.6126 - val_loss: 15.2535 - val_acc: 0.4947
# Epoch 3/30
# 414/414 [==============================] - 164s 395ms/step - loss: 17.3704 - acc: 0.7188 - val_loss: 21.3025 - val_acc: 0.4839
# Epoch 4/30
# 414/414 [==============================] - 309s 746ms/step - loss: 23.1366 - acc: 0.7534 - val_loss: 26.9121 - val_acc: 0.6023
# Epoch 5/30
# 414/414 [==============================] - 291s 703ms/step - loss: 28.1043 - acc: 0.7672 - val_loss: 30.8339 - val_acc: 0.5827

#  model 12

# classifier.add(Convolution2D(64, kernel_size=4, strides=1, activation='relu', input_shape=(64, 64, 3)))
# classifier.add(Convolution2D(64, kernel_size=4, strides=2, activation='relu'))
# classifier.add(Dropout(0.5))
# classifier.add(Convolution2D(128, kernel_size=4, strides=1, activation='relu'))
# classifier.add(Convolution2D(128, kernel_size=4, strides=2, activation='relu'))
# classifier.add(Dropout(0.5))
# classifier.add(Convolution2D(256, kernel_size=4, strides=1, activation='relu'))
# classifier.add(Convolution2D(256, kernel_size=4, strides=2, activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Flatten())
# classifier.add(Dense(512, activation='relu'))
# classifier.add(Dropout(0.5))
# classifier.add(Dense(units=24, activation='softmax'))

# # output 15

# (keras) C:\Users\anwar\gitkraken\Deeplearning Exercise\keras\dropout>python test-other.py
# Using TensorFlow backend.
# Found 52992 images belonging to 24 classes.
# Found 12782 images belonging to 24 classes.
# Epoch 1/30
# 414/414 [==============================] - 101s 243ms/step - loss: 2.2179 - acc: 0.2841 - val_loss: 1.6590 - val_acc: 0.5037
# Epoch 2/30
# 414/414 [==============================] - 98s 236ms/step - loss: 1.0559 - acc: 0.6513 - val_loss: 1.3728 - val_acc: 0.6218
# Epoch 3/30
# 414/414 [==============================] - 96s 233ms/step - loss: 0.6659 - acc: 0.7835 - val_loss: 1.4571 - val_acc: 0.6737
#.................................................................
# Epoch 28/30
# 414/414 [==============================] - 97s 234ms/step - loss: 0.1170 - acc: 0.9632 - val_loss: 1.2066 - val_acc: 0.7647
# Epoch 29/30
# 414/414 [==============================] - 97s 234ms/step - loss: 0.1284 - acc: 0.9599 - val_loss: 1.1428 - val_acc: 0.7215
# Epoch 30/30
# 414/414 [==============================] - 97s 235ms/step - loss: 0.1134 - acc: 0.9654 - val_loss: 1.1155 - val_acc: 0.7571

# kernel 4

# output 16

# 414/414 [==============================] - 132s 319ms/step - loss: 1.8288 - acc: 0.4098 - val_loss: 1.4667 - val_acc: 0.5800
# Epoch 2/30
# 414/414 [==============================] - 115s 278ms/step - loss: 0.6857 - acc: 0.7780 - val_loss: 1.2469 - val_acc: 0.6760
#..........................
# Epoch 9/30
# 414/414 [==============================] - 109s 263ms/step - loss: 0.1272 - acc: 0.9592 - val_loss: 0.7636 - val_acc: 0.8013
# Epoch 10/30
# 414/414 [==============================] - 109s 264ms/step - loss: 0.1207 - acc: 0.9621 - val_loss: 1.0548 - val_acc: 0.7974
# Epoch 11/30
# 414/414 [==============================] - 109s 263ms/step - loss: 0.1095 - acc: 0.9645 - val_loss: 0.7735 - val_acc: 0.8009
# Epoch 12/30
# 414/414 [==============================] - 109s 264ms/step - loss: 0.1095 - acc: 0.9659 - val_loss: 1.0797 - val_acc: 0.8026
#..........................................
# Epoch 29/30
# 414/414 [==============================] - 98s 237ms/step - loss: 0.0646 - acc: 0.9808 - val_loss: 1.0133 - val_acc: 0.7730
# Epoch 30/30
# 414/414 [==============================] - 98s 236ms/step - loss: 0.0647 - acc: 0.9804 - val_loss: 1.1267 - val_acc: 0.7689


#  model 13

# classifier.add(Convolution2D(64, (3, 3), activation='relu', input_shape=(64, 64, 3)))
# classifier.add(Convolution2D(64, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Dropout(0.5))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Dropout(0.5))
# classifier.add(Convolution2D(256, (3, 3), activation='relu'))
# classifier.add(Convolution2D(256, (3, 3), activation='relu'))
# classifier.add(Dropout(0.5))
# classifier.add(Convolution2D(512, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Dropout(0.5))
# classifier.add(Flatten())
# classifier.add(Dense(512, activation='relu'))
# classifier.add(Dropout(0.5))
# classifier.add(Dense(units=24, activation='softmax'))

# output 17

# 824/824 [==============================] - 122s 148ms/step - loss: 2.0938 - acc: 0.3174 - val_loss: 1.3834 - val_acc: 0.6216
# Epoch 2/50
# 824/824 [==============================] - 117s 143ms/step - loss: 1.1048 - acc: 0.6308 - val_loss: 1.3864 - val_acc: 0.6152
#.....................................
# Epoch 9/50
# 824/824 [==============================] - 117s 142ms/step - loss: 0.4005 - acc: 0.8740 - val_loss: 0.7628 - val_acc: 0.7633
# Epoch 10/50
# 824/824 [==============================] - 118s 143ms/step - loss: 0.3880 - acc: 0.8785 - val_loss: 0.7197 - val_acc: 0.7785

#  model 14
# # adding layers
# classifier.add(Convolution2D(64, (3, 3), activation='relu', input_shape=(64, 64, 3)))
# classifier.add(BatchNormalization())
# classifier.add(Convolution2D(64, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(BatchNormalization())
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))
# classifier.add(Convolution2D(256, (3, 3), activation='relu'))
# classifier.add(BatchNormalization())
# classifier.add(Convolution2D(256, (3, 3), activation='relu'))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))
# classifier.add(Convolution2D(512, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))
# classifier.add(Flatten())
# classifier.add(Dense(512, activation='relu'))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))
# classifier.add(Dense(units=24, activation='softmax'))

# output 18

# 824/824 [==============================] - 141s 171ms/step - loss: 1.5476 - acc: 0.5390 - val_loss: 2.0532 - val_acc: 0.5083
# Epoch 2/50
# 824/824 [==============================] - 137s 166ms/step - loss: 0.5914 - acc: 0.8072 - val_loss: 1.1877 - val_acc: 0.6741
# Epoch 3/50
# 824/824 [==============================] - 136s 165ms/step - loss: 0.3929 - acc: 0.8723 - val_loss: 1.2306 - val_acc: 0.7244
#...................................
# Epoch 9/50
# 824/824 [==============================] - 142s 172ms/step - loss: 0.1377 - acc: 0.9554 - val_loss: 0.9047 - val_acc: 0.7939
# Epoch 10/50
# 824/824 [==============================] - 152s 185ms/step - loss: 0.1312 - acc: 0.9578 - val_loss: 1.0224 - val_acc: 0.7877


#  model 15

# classifier.add(Convolution2D(64, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.0001), input_shape=(64, 64, 3)))
# classifier.add(BatchNormalization())
# classifier.add(Convolution2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))
# classifier.add(Convolution2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(BatchNormalization())
# classifier.add(Convolution2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))
# # classifier.add(Convolution2D(256, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# # classifier.add(BatchNormalization())
# classifier.add(Convolution2D(256, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(BatchNormalization())
# classifier.add(Convolution2D(256, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# # classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))
# # classifier.add(Convolution2D(512, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# # classifier.add(BatchNormalization())
# # classifier.add(Convolution2D(512, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# # classifier.add(BatchNormalization())
# classifier.add(Convolution2D(512, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))
# classifier.add(Flatten())
# classifier.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))
# classifier.add(Dense(units=24, activation='softmax'))

# output 19

# 824/824 [==============================] - 144s 175ms/step - loss: 1.7905 - acc: 0.5395 - val_loss: 2.1141 - val_acc: 0.6028
# Epoch 2/50
# 824/824 [==============================] - 139s 169ms/step - loss: 0.9042 - acc: 0.7990 - val_loss: 1.7826 - val_acc: 0.6514
#........................................
# Epoch 8/50
# 824/824 [==============================] - 138s 168ms/step - loss: 0.7714 - acc: 0.9327 - val_loss: 1.4493 - val_acc: 0.7836
# Epoch 9/50
# 824/824 [==============================] - 139s 169ms/step - loss: 0.7730 - acc: 0.9389 - val_loss: 1.4876 - val_acc: 0.7745
# Epoch 10/50
# 824/824 [==============================] - 139s 168ms/step - loss: 0.7846 - acc: 0.9423 - val_loss: 1.9426 - val_acc: 0.7040


#  model 16

# classifier.add(Convolution2D(64, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.0001), input_shape=(80, 80, 3)))
# classifier.add(BatchNormalization())
# classifier.add(Convolution2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))

# classifier.add(Convolution2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(BatchNormalization())
# classifier.add(Convolution2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))

# classifier.add(Convolution2D(256, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(BatchNormalization())
# classifier.add(Convolution2D(256, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))

# classifier.add(Convolution2D(512, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(BatchNormalization())
# classifier.add(Convolution2D(512, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))

# classifier.add(Flatten())
# classifier.add(Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))
# classifier.add(Dense(units=24, activation='softmax'))

# output 20

# 824/824 [==============================] - 214s 259ms/step - loss: 1.8567 - acc: 0.5347 - val_loss: 2.1153 - val_acc: 0.5568
# Epoch 2/50
# 824/824 [==============================] - 202s 246ms/step - loss: 0.9299 - acc: 0.8004 - val_loss: 1.8727 - val_acc: 0.6264
#...............................................
# 824/824 [==============================] - 206s 250ms/step - loss: 0.8726 - acc: 0.9498 - val_loss: 2.2785 - val_acc: 0.6394
# Epoch 16/50
# 824/824 [==============================] - 204s 247ms/step - loss: 0.8603 - acc: 0.9500 - val_loss: 1.6192 - val_acc: 0.7693


#  model 17

# classifier.add(Convolution2D(64, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.0001), input_shape=(80, 80, 3)))
# classifier.add(BatchNormalization())
# classifier.add(Convolution2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))

# classifier.add(Convolution2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.3))
# classifier.add(Convolution2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))

# classifier.add(Convolution2D(256, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.3))
# classifier.add(Convolution2D(256, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))

# classifier.add(Convolution2D(512, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.3))
# classifier.add(Convolution2D(512, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))

# classifier.add(Flatten())
# classifier.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))
# classifier.add(Dense(units=24, activation='softmax'))

# output 21

# 824/824 [==============================] - 222s 269ms/step - loss: 2.0927 - acc: 0.4530 - val_loss: 2.5753 - val_acc: 0.4415
# Epoch 2/50
# 824/824 [==============================] - 217s 264ms/step - loss: 1.0361 - acc: 0.7527 - val_loss: 1.6586 - val_acc: 0.6728
# Epoch 3/50
# 824/824 [==============================] - 215s 261ms/step - loss: 0.8411 - acc: 0.8317 - val_loss: 1.5803 - val_acc: 0.6948
# Epoch 4/50
# 824/824 [==============================] - 215s 261ms/step - loss: 0.7785 - acc: 0.8713 - val_loss: 1.5302 - val_acc: 0.7061
# Epoch 5/50
# 824/824 [==============================] - 215s 261ms/step - loss: 0.7647 - acc: 0.8947 - val_loss: 1.8803 - val_acc: 0.6997
# Epoch 6/50
# 824/824 [==============================] - 215s 261ms/step - loss: 0.8005 - acc: 0.9078 - val_loss: 1.7714 - val_acc: 0.6880
# Epoch 7/50
# 824/824 [==============================] - 215s 261ms/step - loss: 0.8258 - acc: 0.9182 - val_loss: 2.1804 - val_acc: 0.7305


#  model 18

# classifier.add(Convolution2D(64, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.0001), input_shape=(80, 80, 3)))
# classifier.add(BatchNormalization())
# classifier.add(Convolution2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))

# classifier.add(Convolution2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(BatchNormalization())
# classifier.add(Convolution2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))

# classifier.add(Convolution2D(256, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(BatchNormalization())
# classifier.add(Convolution2D(256, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))

# classifier.add(Convolution2D(512, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))

# classifier.add(Flatten())
# classifier.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
# classifier.add(BatchNormalization())
# classifier.add(Dropout(0.5))
# classifier.add(Dense(units=24, activation='softmax'))

# output 22

# 824/824 [==============================] - 199s 241ms/step - loss: 1.7475 - acc: 0.5435 - val_loss: 2.8043 - val_acc: 0.4461
# Epoch 2/50
# 824/824 [==============================] - 194s 235ms/step - loss: 0.8673 - acc: 0.8005 - val_loss: 1.2742 - val_acc: 0.7147
# Epoch 3/50
#......................................................
# Epoch 19/50
# 824/824 [==============================] - 229s 278ms/step - loss: 0.7260 - acc: 0.9552 - val_loss: 1.6744 - val_acc: 0.7528
# Epoch 20/50
# 824/824 [==============================] - 201s 244ms/step - loss: 0.7129 - acc: 0.9580 - val_loss: 1.7363 - val_acc: 0.7504
# Epoch 21/50
# 824/824 [==============================] - 198s 241ms/step - loss: 0.7184 - acc: 0.9564 - val_loss: 1.8706 - val_acc: 0.7373


#  model 19

# classifier.add(Convolution2D(64, (3, 3), activation='relu', input_shape=(64, 64, 3)))
# classifier.add(Convolution2D(64, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Dropout(0.3))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(Convolution2D(128, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Dropout(0.3))
# classifier.add(Convolution2D(256, (3, 3), activation='relu'))
# classifier.add(Convolution2D(256, (3, 3), activation='relu'))
# classifier.add(MaxPooling2D(pool_size=(2, 2)))
# classifier.add(Dropout(0.3))


# output 23

# (keras) C:\Users\anwar\gitkraken\Deeplearning Exercise\keras\dropout>python test-other.py
# Using TensorFlow backend.
# Found 52992 images belonging to 24 classes.
# Found 12782 images belonging to 24 classes.

# Epoch 1/50
# 828/828 [==============================] - 114s 138ms/step - loss: 1.6435 - acc: 0.4768 - val_loss: 1.3391 - val_acc: 0.6606
# Epoch 2/50
# 828/828 [==============================] - 107s 129ms/step - loss: 0.6072 - acc: 0.8049 - val_loss: 0.9690 - val_acc: 0.7402
# Epoch 3/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.3867 - acc: 0.8754 - val_loss: 1.0148 - val_acc: 0.7677
# Epoch 4/50
# 828/828 [==============================] - 111s 134ms/step - loss: 0.3012 - acc: 0.9037 - val_loss: 1.1486 - val_acc: 0.7386
# Epoch 5/50
# 828/828 [==============================] - 146s 176ms/step - loss: 0.2486 - acc: 0.9204 - val_loss: 0.8903 - val_acc: 0.7944
# Epoch 6/50
# 828/828 [==============================] - 117s 142ms/step - loss: 0.2236 - acc: 0.9276 - val_loss: 1.2478 - val_acc: 0.7387
# Epoch 7/50
# 828/828 [==============================] - 146s 176ms/step - loss: 0.1990 - acc: 0.9366 - val_loss: 0.7724 - val_acc: 0.8002
# Epoch 8/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.1755 - acc: 0.9446 - val_loss: 0.9927 - val_acc: 0.7787
# Epoch 9/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.1665 - acc: 0.9459 - val_loss: 0.9318 - val_acc: 0.7940
# Epoch 10/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.1538 - acc: 0.9509 - val_loss: 0.8387 - val_acc: 0.8056
# Epoch 11/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.1442 - acc: 0.9547 - val_loss: 0.9033 - val_acc: 0.7944
# Epoch 12/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.1358 - acc: 0.9578 - val_loss: 1.0541 - val_acc: 0.7986
# Epoch 13/50
# 828/828 [==============================] - 107s 129ms/step - loss: 0.1346 - acc: 0.9585 - val_loss: 0.9294 - val_acc: 0.8023
# Epoch 14/50
# 828/828 [==============================] - 107s 129ms/step - loss: 0.1275 - acc: 0.9600 - val_loss: 0.7287 - val_acc: 0.8163
# Epoch 15/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.1189 - acc: 0.9618 - val_loss: 1.3417 - val_acc: 0.7570
# Epoch 16/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.1157 - acc: 0.9640 - val_loss: 0.7194 - val_acc: 0.8136
# Epoch 17/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.1094 - acc: 0.9657 - val_loss: 0.9110 - val_acc: 0.8084
# Epoch 18/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.1134 - acc: 0.9653 - val_loss: 0.8777 - val_acc: 0.8138
# Epoch 19/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.1086 - acc: 0.9662 - val_loss: 0.9924 - val_acc: 0.8138
# Epoch 20/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.1023 - acc: 0.9683 - val_loss: 0.8889 - val_acc: 0.8166
# Epoch 21/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.1063 - acc: 0.9667 - val_loss: 1.9606 - val_acc: 0.7053
# Epoch 22/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.1006 - acc: 0.9691 - val_loss: 0.9985 - val_acc: 0.8042
# Epoch 23/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.1015 - acc: 0.9691 - val_loss: 0.8698 - val_acc: 0.8124
# Epoch 24/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.0952 - acc: 0.9710 - val_loss: 0.7670 - val_acc: 0.8385
# Epoch 25/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.1004 - acc: 0.9698 - val_loss: 0.8617 - val_acc: 0.8222
# Epoch 26/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.0892 - acc: 0.9729 - val_loss: 0.9575 - val_acc: 0.8299
# Epoch 27/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.1004 - acc: 0.9697 - val_loss: 0.9877 - val_acc: 0.8085
# Epoch 28/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.0949 - acc: 0.9710 - val_loss: 1.0059 - val_acc: 0.8036
# Epoch 29/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.0962 - acc: 0.9722 - val_loss: 1.0080 - val_acc: 0.8517
# Epoch 30/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.0895 - acc: 0.9731 - val_loss: 1.0008 - val_acc: 0.8214
# Epoch 31/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.0947 - acc: 0.9721 - val_loss: 0.8818 - val_acc: 0.8357
# Epoch 32/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.0927 - acc: 0.9731 - val_loss: 0.9528 - val_acc: 0.8273
# Epoch 33/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.0920 - acc: 0.9718 - val_loss: 0.9600 - val_acc: 0.8154
# Epoch 34/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.0915 - acc: 0.9724 - val_loss: 1.2598 - val_acc: 0.8067
# Epoch 35/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.0922 - acc: 0.9727 - val_loss: 1.0861 - val_acc: 0.7967
# Epoch 36/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.0949 - acc: 0.9717 - val_loss: 0.9112 - val_acc: 0.8281
# Epoch 37/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.0853 - acc: 0.9744 - val_loss: 1.0259 - val_acc: 0.8344
# Epoch 38/50
# 828/828 [==============================] - 108s 131ms/step - loss: 0.0913 - acc: 0.9739 - val_loss: 1.0453 - val_acc: 0.8338
# Epoch 39/50
# 828/828 [==============================] - 108s 131ms/step - loss: 0.0909 - acc: 0.9740 - val_loss: 0.9800 - val_acc: 0.8272
# Epoch 40/50
# 828/828 [==============================] - 131s 158ms/step - loss: 0.0918 - acc: 0.9731 - val_loss: 0.8139 - val_acc: 0.8482
# Epoch 41/50
# 828/828 [==============================] - 110s 132ms/step - loss: 0.0879 - acc: 0.9748 - val_loss: 1.1470 - val_acc: 0.8184
# Epoch 42/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.0883 - acc: 0.9754 - val_loss: 0.8945 - val_acc: 0.8443
# Epoch 43/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.0912 - acc: 0.9743 - val_loss: 0.8151 - val_acc: 0.8559
# Epoch 44/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.0877 - acc: 0.9743 - val_loss: 0.8367 - val_acc: 0.8311
# Epoch 45/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.0919 - acc: 0.9739 - val_loss: 1.1422 - val_acc: 0.8095
# Epoch 46/50
# 828/828 [==============================] - 107s 130ms/step - loss: 0.0905 - acc: 0.9738 - val_loss: 0.7145 - val_acc: 0.8572
# Epoch 47/50
# 828/828 [==============================] - 106s 129ms/step - loss: 0.0886 - acc: 0.9748 - val_loss: 0.8671 - val_acc: 0.8384
# Epoch 48/50
# 828/828 [==============================] - 107s 129ms/step - loss: 0.0875 - acc: 0.9751 - val_loss: 0.9159 - val_acc: 0.8357
# Epoch 49/50
# 828/828 [==============================] - 106s 129ms/step - loss: 0.0917 - acc: 0.9740 - val_loss: 0.8323 - val_acc: 0.8584
# Epoch 50/50
# 828/828 [==============================] - 106s 128ms/step - loss: 0.0831 - acc: 0.9765 - val_loss: 0.8589 - val_acc: 0.8444